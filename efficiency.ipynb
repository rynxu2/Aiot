{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from models import SEQUENCE_LENGTH, N_FEATURES, HIDDEN_SIZE, NUM_LAYERS, NUM_HEADS\n",
    "from models import TransformerModel\n",
    "from models import TransformerModelChatGPT\n",
    "from models import TransformerModelClaudeOptimal\n",
    "from models import TransformerModelCopilotOptimal\n",
    "from models import TransformerModelCursorOptimal\n",
    "from models import TransformerModelDeepseek\n",
    "from models import TransformerModelDeepseekOptimal\n",
    "from models import TransformerModelGrok\n",
    "from models import TransformerModelGrokOptimal\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "class ActivityDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = sequences\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]\n",
    "\n",
    "def prepare_sequences(data, sequence_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    for i in range(0, len(data) - sequence_length, sequence_length//2):  # 50% overlap\n",
    "        seq = data[i:i + sequence_length]\n",
    "        if len(seq) == sequence_length:\n",
    "            sequences.append(seq)\n",
    "            labels.append(seq['ActivityLabel'].mode()[0])  # Most common label in sequence\n",
    "    \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "df = pd.read_csv('data\\\\combined\\\\merged_users_corrected.csv')\n",
    "    \n",
    "# Prepare features and labels\n",
    "features = ['AccelX', 'AccelY', 'AccelZ', 'GyroX', 'GyroY', 'GyroZ']\n",
    "X = df[features]\n",
    "y = df['ActivityLabel']\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Create sequences\n",
    "X_scaled['ActivityLabel'] = y_encoded\n",
    "sequences, labels = prepare_sequences(X_scaled, SEQUENCE_LENGTH)\n",
    "\n",
    "# Remove ActivityLabel column from sequences\n",
    "sequences = sequences[:, :, :-1].astype(np.float32)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    sequences, labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = ActivityDataset(torch.FloatTensor(X_train), torch.LongTensor(y_train))\n",
    "test_dataset = ActivityDataset(torch.FloatTensor(X_test), torch.LongTensor(y_test))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Loss: 9.2468 | Accuracy: 0.2686 | F1-Score: 0.1213\n",
      "1 - Loss: 0.1725 | Accuracy: 0.9675 | F1-Score: 0.9674\n",
      "2 - Loss: 1.7556 | Accuracy: 0.6684 | F1-Score: 0.6674\n",
      "3 - Loss: 0.4366 | Accuracy: 0.9203 | F1-Score: 0.9195\n",
      "4 - Loss: 0.2964 | Accuracy: 0.9465 | F1-Score: 0.9467\n",
      "5 - Loss: 0.6170 | Accuracy: 0.9171 | F1-Score: 0.9169\n",
      "6 - Loss: 0.3698 | Accuracy: 0.9328 | F1-Score: 0.9322\n",
      "7 - Loss: 0.4115 | Accuracy: 0.9412 | F1-Score: 0.9392\n",
      "8 - Loss: 0.4060 | Accuracy: 0.9318 | F1-Score: 0.9297\n",
      "\n",
      "Model Acc tốt nhất: 1 với Accuracy: 0.9675\n",
      "\n",
      "Model F1 tốt nhất: 1 với F1: 0.9674\n"
     ]
    }
   ],
   "source": [
    "def load_model(model_index, model_path, num_features, num_classes, device):\n",
    "    list_models = [\n",
    "        TransformerModel,\n",
    "        TransformerModelDeepseek,\n",
    "        TransformerModelChatGPT,\n",
    "        TransformerModelGrok,\n",
    "        TransformerModelGrokOptimal,\n",
    "        TransformerModelClaudeOptimal,\n",
    "        TransformerModelDeepseekOptimal,\n",
    "        TransformerModelCursorOptimal,\n",
    "        TransformerModelCopilotOptimal\n",
    "    ]\n",
    "    model = list_models[model_index](\n",
    "        input_size=num_features,\n",
    "        hidden_size=64,\n",
    "        num_layers=3,\n",
    "        num_heads=4,\n",
    "        num_classes=num_classes\n",
    "    ).to(device)\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Hàm đánh giá mô hình\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == y).sum().item()\n",
    "            total += y.size(0)\n",
    "            \n",
    "            y_true.extend(y.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return avg_loss, acc, f1\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Tiêu chí đánh giá\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Danh sách các mô hình cần so sánh\n",
    "model_paths = [\n",
    "    \"results\\\\MinMaxScaler\\\\2\\\\TransformerModel_w100.pth\", \n",
    "    \"results\\\\MinMaxScaler\\\\2\\\\TransformerModelDeepseek_w100.pth\", \n",
    "    \"results\\\\MinMaxScaler\\\\2\\\\TransformerModelChatGPT_w100.pth\", \n",
    "    \"results\\\\MinMaxScaler\\\\2\\\\TransformerModelGrok_w100.pth\", \n",
    "    'results\\\\MinMaxScaler\\\\2\\\\TransformerModelGrokOptimal_w100.pth', \n",
    "    'results\\\\MinMaxScaler\\\\2\\\\TransformerModelClaudeOptimal_w100.pth', \n",
    "    'results\\\\MinMaxScaler\\\\2\\\\TransformerModelDeepseekOptimal_w100.pth',\n",
    "    'results\\\\MinMaxScaler\\\\2\\\\TransformerModelCursorOptimal_w100.pth',\n",
    "    'results\\\\MinMaxScaler\\\\2\\\\TransformerModelCopilotOptimal_w100.pth'\n",
    "]\n",
    "results = {}\n",
    "\n",
    "# Đánh giá từng mô hình\n",
    "for index in range(len(model_paths)):\n",
    "    model = load_model(index, model_paths[index], num_features=6, num_classes=6, device=device)\n",
    "    test_loss, test_acc, test_f1 = evaluate_model(model, test_loader, criterion, device)\n",
    "    results[index] = {\"Loss\": test_loss, \"Accuracy\": test_acc, \"F1\": test_f1}\n",
    "    print(f\"{index} - Loss: {test_loss:.4f} | Accuracy: {test_acc:.4f} | F1-Score: {test_f1:.4f}\")\n",
    "\n",
    "best_model_acc = max(results, key=lambda x: results[x][\"Accuracy\"])\n",
    "best_model_f1 = max(results, key=lambda x: results[x][\"F1\"])\n",
    "print(f\"\\nModel Acc tốt nhất: {best_model_acc} với Accuracy: {results[best_model_acc]['Accuracy']:.4f}\")\n",
    "print(f\"\\nModel F1 tốt nhất: {best_model_f1} với F1: {results[best_model_f1]['F1']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m best_model_path \u001b[38;5;241m=\u001b[39m model_paths[\u001b[43mbest_model\u001b[49m]\n\u001b[0;32m      7\u001b[0m best_model \u001b[38;5;241m=\u001b[39m load_model(best_model, best_model_path, num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m best_model\u001b[38;5;241m.\u001b[39meval()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Tạo confusion matrix cho mô hình tốt nhất\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "best_model_path = model_paths[best_model]\n",
    "best_model = load_model(best_model, best_model_path, num_features=6, num_classes=6, device=device)\n",
    "best_model.eval()\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = best_model(x)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_true.extend(y.cpu().numpy())\n",
    "        y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Tính confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Vẽ confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Nhãn thực tế')\n",
    "plt.xlabel('Nhãn dự đoán')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
