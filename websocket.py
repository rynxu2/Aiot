import asyncio
import websockets
import struct
import signal
import sys
import torch
import numpy as np
from collections import deque
import torch.nn as nn

HOST = "0.0.0.0"
PORT = 8080
WINDOW_SIZE = 50
STEP_SIZE = 10
received_count = 0
data_buffer = deque(maxlen=WINDOW_SIZE)  

received_count = 0

class HARTransformer(nn.Module):
    def __init__(self, input_dim, num_classes, num_heads=4, num_layers=2, hidden_dim=128):
        super(HARTransformer, self).__init__()
        self.embedding = nn.Linear(input_dim, hidden_dim)
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(d_model=hidden_dim, nhead=num_heads, dropout=0.1),
            num_layers=num_layers
        )
        self.fc = nn.Linear(hidden_dim, num_classes)

    def forward(self, x):
        x = self.embedding(x) 
        x = x.permute(1, 0, 2) 
        x = self.transformer(x)  
        x = x.permute(1, 0, 2)
        x = x.mean(dim=1)
        x = self.fc(x)
        return x

def load_transformer_model(model_path):
    try:
        model = torch.load(model_path, map_location=torch.device('cpu'))
        model.eval()
        print("‚úÖ Loaded Transformer model successfully")
        return model
    except Exception as e:
        print(f"‚ùå Error loading model: {e}")
        return None

# Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
def preprocess_data(data_window):
    if len(data_window) < WINDOW_SIZE:
        return None
    
    # Chuy·ªÉn d·ªØ li·ªáu th√†nh numpy array
    data_array = np.array(data_window)
    
    # Chu·∫©n h√≥a d·ªØ li·ªáu (c√≥ th·ªÉ ƒëi·ªÅu ch·ªânh theo preprocessing c·ªßa b·∫°n)
    mean = np.mean(data_array, axis=0)
    std = np.std(data_array, axis=0)
    normalized_data = (data_array - mean) / (std + 1e-8)
    
    # Chuy·ªÉn th√†nh tensor
    data_tensor = torch.FloatTensor(normalized_data).unsqueeze(0)  # Th√™m batch dimension
    return data_tensor

# H√†m d·ª± ƒëo√°n ho·∫°t ƒë·ªông
def predict_activity(model, data_tensor):
    with torch.no_grad():
        outputs = model(data_tensor)
        # Gi·∫£ s·ª≠ output l√† logits cho c√°c l·ªõp ho·∫°t ƒë·ªông
        predicted = torch.argmax(outputs, dim=-1)
        return predicted.item()
    
ACTIVITY_LABELS = {
    0: "walking",
    1: "jogging",
    2: "sitting",
    3: "standing",
    4: "jumping",
    5: "falling"
}

async def handler(websocket, path):
    global received_count
    print("Client connected")

    model = HARTransformer(input_dim=6, num_classes=6)
    state_dict = torch.load("best_model.pth", map_location=torch.device('cpu'))
    model.load_state_dict(state_dict)
    model.eval()
    
    try:
        async for data in websocket:
            if len(data) == 24:
                ax, ay, az, gx, gy, gz = struct.unpack('ffffff', data)
                received_count += 1
                
                data_buffer.append([ax, ay, az, gx, gy, gz])
                
                if len(data_buffer) == WINDOW_SIZE and received_count % STEP_SIZE == 0:
                    # Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
                    input_tensor = preprocess_data(data_buffer)
                    if input_tensor is not None:
                        # D·ª± ƒëo√°n ho·∫°t ƒë·ªông
                        activity_idx = predict_activity(model, input_tensor)
                        activity_name = ACTIVITY_LABELS.get(activity_idx, "unknown")
                        
                        # In k·∫øt qu·∫£ d·ª± ƒëo√°n
                        print(f"ü§ñ Predicted Activity: {activity_name}")
                        
                        # G·ª≠i k·∫øt qu·∫£ v·ªÅ client
                        response = {
                            "status": "success",
                            "activity": activity_name,
                            "confidence": 1.0  # C√≥ th·ªÉ th√™m confidence score n·∫øu c·∫ßn
                        }
                        await websocket.send(str(response))
                else:
                    await websocket.send("ACK")
    except websockets.ConnectionClosed:
        print("Client disconnected")
    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")

async def main():
    try:
        server = await websockets.serve(handler, HOST, PORT)
        print(f"‚úÖ WebSocket server running on ws://{HOST}:{PORT}")
        await server.wait_closed()
    except Exception as e:
        print(f"‚ùå Server error: {e}")

# üìå X·ª≠ l√Ω khi nh·∫•n Ctrl + C
def signal_handler(sig, frame):
    print("\nüõë Stopping server...")
    loop = asyncio.get_event_loop()
    loop.stop()
    sys.exit(0)

if __name__ == "__main__":
    signal.signal(signal.SIGINT, signal_handler)
    loop = asyncio.get_event_loop()
    loop.set_exception_handler(lambda loop, context: print(f"‚ö†Ô∏è Exception: {context['message']}"))
    
    try:
        loop.run_until_complete(main())
    except KeyboardInterrupt:
        print("üõë Server stopped by user.")
    except Exception as e:
        print(f"‚ùå Critical error: {e}")
    finally:
        loop.close()
